{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GOLD: Height/Reach Advantage Impact\n",
        "\n",
        "Analyzes correlation between size advantage (height, reach) and win rate. Builds materialized bins and optional correlation outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Bootstrap\n",
        "try:\n",
        "    dbutils.widgets.text(\"storage_account\", \"storagetmufc\")\n",
        "    dbutils.widgets.text(\"secret_scope\", \"kv-scope\")\n",
        "    dbutils.widgets.text(\"key_name\", \"adls-account-key\")\n",
        "    dbutils.widgets.text(\"silver_db\", \"ufc_silver\")\n",
        "    dbutils.widgets.text(\"gold_db\", \"ufc_gold\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "silver_db = dbutils.widgets.get(\"silver_db\") if 'dbutils' in globals() else \"ufc_silver\"\n",
        "gold_db = dbutils.widgets.get(\"gold_db\") if 'dbutils' in globals() else \"ufc_gold\"\n",
        "\n",
        "try:\n",
        "    storage_account = dbutils.widgets.get(\"storage_account\")\n",
        "    secret_scope = dbutils.widgets.get(\"secret_scope\")\n",
        "    key_name = dbutils.widgets.get(\"key_name\")\n",
        "    account_key = dbutils.secrets.get(secret_scope, key_name)\n",
        "    spark.conf.set(f\"fs.azure.account.key.{storage_account}.dfs.core.windows.net\", account_key)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    spark.sql(\"USE CATALOG hive_metastore\")\n",
        "except Exception:\n",
        "    try:\n",
        "        spark.catalog.setCurrentCatalog(\"hive_metastore\")\n",
        "    except Exception:\n",
        "        pass\n",
        "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {silver_db}\")\n",
        "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {gold_db}\")\n",
        "print(\"Silver DB:\", silver_db, \"| Gold DB:\", gold_db)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load silver\n",
        "fights = spark.table(f\"hive_metastore.{silver_db}.espn_fights_silver\")\n",
        "ath = spark.table(f\"hive_metastore.{silver_db}.espn_athletes_silver\")\n",
        "\n",
        "# Two rows per fight\n",
        "left = (fights\n",
        "    .select(\"competition_id\",\"event_id\",\"event_date\",\"event_year\",\"weight_class\",\n",
        "            F.col(\"fighter_a_name\").alias(\"athlete_name\"), F.col(\"fighter_a_winner\").alias(\"is_winner\"))\n",
        "    .withColumn(\"side\", F.lit(\"A\")))\n",
        "right = (fights\n",
        "    .select(\"competition_id\",\"event_id\",\"event_date\",\"event_year\",\"weight_class\",\n",
        "            F.col(\"fighter_b_name\").alias(\"athlete_name\"), F.col(\"fighter_b_winner\").alias(\"is_winner\"))\n",
        "    .withColumn(\"side\", F.lit(\"B\")))\n",
        "rows = left.unionByName(right)\n",
        "\n",
        "# Map name -> athlete_id\n",
        "names = (ath.select(F.col(\"full_name\").alias(\"n1\"), F.col(\"display_name\").alias(\"n2\"), \"athlete_id\"))\n",
        "rows = (rows.join(names, (F.lower(\"athlete_name\") == F.lower(\"n1\")) | (F.lower(\"athlete_name\") == F.lower(\"n2\")), \"left\"))\n",
        "\n",
        "feat = (rows.alias(\"x\")\n",
        "    .join(ath.alias(\"ax\"), F.col(\"x.athlete_id\") == F.col(\"ax.athlete_id\"), \"left\")\n",
        "    .join(rows.alias(\"y\"), (F.col(\"x.competition_id\") == F.col(\"y.competition_id\")) & (F.col(\"x.side\") != F.col(\"y.side\")), \"inner\")\n",
        "    .join(ath.alias(\"ay\"), F.col(\"y.athlete_id\") == F.col(\"ay.athlete_id\"), \"left\")\n",
        "    .select(\n",
        "        F.col(\"x.competition_id\").alias(\"competition_id\"),\n",
        "        F.col(\"x.event_id\").alias(\"event_id\"),\n",
        "        F.col(\"x.event_date\").alias(\"event_date\"),\n",
        "        F.col(\"x.event_year\").alias(\"event_year\"),\n",
        "        F.col(\"x.weight_class\").alias(\"weight_class\"),\n",
        "        F.col(\"x.is_winner\").alias(\"is_winner\"),\n",
        "        (F.col(\"ax.height_cm\") - F.col(\"ay.height_cm\")).alias(\"height_adv_cm\"),\n",
        "        (F.col(\"ax.reach_cm\") - F.col(\"ay.reach_cm\")).alias(\"reach_adv_cm\"),\n",
        "        (F.months_between(F.col(\"x.event_date\"), F.col(\"ax.birth_date\"))/12.0 - F.months_between(F.col(\"x.event_date\"), F.col(\"ay.birth_date\"))/12.0).alias(\"age_adv_years\"),\n",
        "    )\n",
        "    .filter(F.col(\"height_adv_cm\").isNotNull() | F.col(\"reach_adv_cm\").isNotNull())\n",
        ")\n",
        "\n",
        "# Clip extremes and bin\n",
        "feat = feat.withColumn(\"height_adv_cm\", F.when(F.col(\"height_adv_cm\") > 25, 25).when(F.col(\"height_adv_cm\") < -25, -25).otherwise(F.col(\"height_adv_cm\")))\n",
        "feat = feat.withColumn(\"reach_adv_cm\", F.when(F.col(\"reach_adv_cm\") > 30, 30).when(F.col(\"reach_adv_cm\") < -30, -30).otherwise(F.col(\"reach_adv_cm\")))\n",
        "\n",
        "bins_h = [-25,-20,-15,-10,-5,0,5,10,15,20,25]\n",
        "bins_r = [-30,-20,-10,0,10,20,30]\n",
        "\n",
        "# helper for bin label\n",
        "def _bin_label(value, edges):\n",
        "    if value is None:\n",
        "        return None\n",
        "    for i in range(len(edges)-1):\n",
        "        if value >= edges[i] and value < edges[i+1]:\n",
        "            return f\"[{edges[i]},{edges[i+1]})\"\n",
        "    if value == edges[-1]:\n",
        "        return f\"[{edges[-2]},{edges[-1]}]\"\n",
        "    return None\n",
        "\n",
        "from pyspark.sql.types import StringType\n",
        "bin_h_udf = F.udf(lambda v: _bin_label(v, bins_h), StringType())\n",
        "bin_r_udf = F.udf(lambda v: _bin_label(v, bins_r), StringType())\n",
        "\n",
        "binned = (feat\n",
        "    .withColumn(\"height_adv_bin\", bin_h_udf(F.col(\"height_adv_cm\")))\n",
        "    .withColumn(\"reach_adv_bin\", bin_r_udf(F.col(\"reach_adv_cm\")))\n",
        "    .filter(F.col(\"height_adv_bin\").isNotNull())\n",
        ")\n",
        "\n",
        "# Aggregations\n",
        "adv_overall = (binned\n",
        "    .groupBy(\"height_adv_bin\")\n",
        "    .agg(F.count(\"*\").alias(\"fights\"), F.sum(F.when(F.col(\"is_winner\") == True, 1).otherwise(0)).alias(\"wins\"))\n",
        "    .withColumn(\"win_rate\", F.col(\"wins\")/F.col(\"fights\"))\n",
        ")\n",
        "\n",
        "# Removed per request: no aggregation by weight class\n",
        "\n",
        "heat_height_reach = (binned\n",
        "    .groupBy(\"height_adv_bin\",\"reach_adv_bin\")\n",
        "    .agg(F.count(\"*\").alias(\"fights\"), F.sum(F.when(F.col(\"is_winner\") == True, 1).otherwise(0)).alias(\"wins\"))\n",
        "    .withColumn(\"win_rate\", F.col(\"wins\")/F.col(\"fights\"))\n",
        ")\n",
        "\n",
        "# Materialize (no by-weight aggregation)\n",
        "adv_overall.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\").saveAsTable(f\"hive_metastore.{gold_db}.mv_height_advantage_bins_overall\")\n",
        "heat_height_reach.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\").saveAsTable(f\"hive_metastore.{gold_db}.mv_height_vs_reach_heatmap\")\n",
        "\n",
        "spark.sql(f\"CREATE OR REPLACE VIEW hive_metastore.{gold_db}.v_height_advantage_bins_overall AS SELECT * FROM hive_metastore.{gold_db}.mv_height_advantage_bins_overall\")\n",
        "spark.sql(f\"CREATE OR REPLACE VIEW hive_metastore.{gold_db}.v_height_vs_reach_heatmap AS SELECT * FROM hive_metastore.{gold_db}.mv_height_vs_reach_heatmap\")\n",
        "\n",
        "# Quick preview\n",
        "display(spark.table(f\"hive_metastore.{gold_db}.mv_height_advantage_bins_overall\").orderBy(\"height_adv_bin\"))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
