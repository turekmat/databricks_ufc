{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UFC Fights Transform & Clean (Bronze -> Silver)\n",
        "\n",
        "Cleans and writes `espn_fights_silver`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime, timezone\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "try:\n",
        "    dbutils.widgets.text(\"storage_account\", \"storagetmufc\")\n",
        "    dbutils.widgets.text(\"secret_scope\", \"kv-scope\")\n",
        "    dbutils.widgets.text(\"key_name\", \"adls-account-key\")\n",
        "    dbutils.widgets.text(\"bronze_db\", \"ufc_bronze\")\n",
        "    dbutils.widgets.text(\"silver_db\", \"ufc_silver\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "storage_account = dbutils.widgets.get(\"storage_account\") if 'dbutils' in globals() else None\n",
        "secret_scope = dbutils.widgets.get(\"secret_scope\") if 'dbutils' in globals() else None\n",
        "key_name = dbutils.widgets.get(\"key_name\") if 'dbutils' in globals() else None\n",
        "bronze_db = dbutils.widgets.get(\"bronze_db\") if 'dbutils' in globals() else \"ufc_bronze\"\n",
        "silver_db = dbutils.widgets.get(\"silver_db\") if 'dbutils' in globals() else \"ufc_silver\"\n",
        "\n",
        "try:\n",
        "    account_key = dbutils.secrets.get(secret_scope, key_name)\n",
        "    spark.conf.set(f\"fs.azure.account.key.{storage_account}.dfs.core.windows.net\", account_key)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    spark.sql(\"USE CATALOG hive_metastore\")\n",
        "except Exception:\n",
        "    try:\n",
        "        spark.catalog.setCurrentCatalog(\"hive_metastore\")\n",
        "    except Exception:\n",
        "        pass\n",
        "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {bronze_db}\")\n",
        "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {silver_db}\")\n",
        "try:\n",
        "    spark.catalog.setCurrentDatabase(bronze_db)\n",
        "except Exception:\n",
        "    spark.sql(f\"USE DATABASE {bronze_db}\")\n",
        "print(\"Bronze DB:\", bronze_db, \"| Silver DB:\", silver_db)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_fights = spark.table(f\"hive_metastore.{bronze_db}.espn_fights\").filter(F.col(\"event_year\").isNotNull())\n",
        "print(\"Fights rows (event_year != null):\", _fights.count())\n",
        "display(_fights.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in _fights.columns]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview BEFORE cleaning (fights)\n",
        "display(_fights.orderBy(F.desc(\"event_date\"), F.asc(\"card_order\")).limit(30))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean fights and write silver\n",
        "SPARSE_THRESHOLD = 0.98\n",
        "# Guard for missing metadata in bronze\n",
        "cols = set(_fights.columns)\n",
        "has_ing = \"ingestion_date\" in cols\n",
        "has_run = \"run_id\" in cols\n",
        "\n",
        "order_exprs = []\n",
        "if has_ing:\n",
        "    order_exprs.append(F.col(\"ingestion_date\").desc())\n",
        "if has_run:\n",
        "    order_exprs.append(F.col(\"run_id\").desc())\n",
        "if not order_exprs and \"event_date\" in cols:\n",
        "    order_exprs.append(F.col(\"event_date\").desc())\n",
        "if not order_exprs:\n",
        "    order_exprs.append(F.lit(0))\n",
        "\n",
        "w = Window.partitionBy(\"event_id\", \"competition_id\").orderBy(*order_exprs)\n",
        "\n",
        "f1 = (_fights\n",
        "    .withColumn(\"weight_class\", F.initcap(F.trim(\"weight_class\")))\n",
        "    .withColumn(\"card_order\", F.col(\"card_order\").cast(\"int\"))\n",
        "    .withColumn(\"fighter_a_name\", F.trim(\"fighter_a_name\"))\n",
        "    .withColumn(\"fighter_b_name\", F.trim(\"fighter_b_name\"))\n",
        "    .withColumn(\"rn\", F.row_number().over(w)).filter(\"rn=1\").drop(\"rn\"))\n",
        "\n",
        "# drop sparse columns\n",
        "counts = _fights.count()\n",
        "nulls = [(c, f1.filter(F.col(c).isNull()).count()) for c in f1.columns]\n",
        "drop_cols = [c for c, n in nulls if counts and n / counts >= SPARSE_THRESHOLD]\n",
        "print(\"Drop cols:\", drop_cols)\n",
        "\n",
        "sel_cols = [\n",
        "    \"competition_id\",\"event_id\",\"event_date\",F.year(\"event_date\").alias(\"event_year\"),\n",
        "    \"weight_class\",\"card_order\",\"status\",\n",
        "    \"fighter_a_name\",\"fighter_a_winner\",\"fighter_b_name\",\"fighter_b_winner\",\n",
        "]\n",
        "if has_ing:\n",
        "    sel_cols.append(\"ingestion_date\")\n",
        "if has_run:\n",
        "    sel_cols.append(\"run_id\")\n",
        "\n",
        "out = f1.drop(*drop_cols).select(*sel_cols)\n",
        "\n",
        "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {silver_db}\")\n",
        "\n",
        "table_name = f\"hive_metastore.{silver_db}.espn_fights_silver\"\n",
        "exists = False\n",
        "try:\n",
        "    spark.table(table_name)\n",
        "    exists = True\n",
        "except Exception:\n",
        "    exists = False\n",
        "\n",
        "if not exists:\n",
        "    out.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\").saveAsTable(table_name)\n",
        "else:\n",
        "    if has_ing and has_run:\n",
        "        tgt = spark.table(table_name).select(\"event_id\", \"competition_id\", \"ingestion_date\", \"run_id\").alias(\"t\")\n",
        "        incr = (out.alias(\"s\")\n",
        "            .join(tgt, on=[\"event_id\",\"competition_id\"], how=\"left\")\n",
        "            .where(F.col(\"t.event_id\").isNull() | (F.col(\"s.ingestion_date\") > F.col(\"t.ingestion_date\")) | ((F.col(\"s.ingestion_date\") == F.col(\"t.ingestion_date\")) & (F.col(\"s.run_id\") > F.col(\"t.run_id\"))))\n",
        "            .select(\"s.*\")\n",
        "        )\n",
        "        incr.createOrReplaceTempView(\"src_fights\")\n",
        "        spark.sql(f\"\"\"\n",
        "            MERGE INTO {table_name} t\n",
        "            USING src_fights s\n",
        "            ON t.event_id = s.event_id AND t.competition_id = s.competition_id\n",
        "            WHEN MATCHED AND (t.ingestion_date < s.ingestion_date OR (t.ingestion_date = s.ingestion_date AND t.run_id < s.run_id)) THEN UPDATE SET *\n",
        "            WHEN NOT MATCHED THEN INSERT *\n",
        "        \"\"\")\n",
        "    else:\n",
        "        # No metadata available â†’ insert only new keys\n",
        "        tgt_keys = spark.table(table_name).select(\"event_id\",\"competition_id\").dropDuplicates()\n",
        "        incr = out.alias(\"s\").join(tgt_keys.alias(\"t\"), on=[\"event_id\",\"competition_id\"], how=\"left_anti\")\n",
        "        if incr.limit(1).count() > 0:\n",
        "            incr.createOrReplaceTempView(\"src_fights\")\n",
        "            spark.sql(f\"\"\"\n",
        "                MERGE INTO {table_name} t\n",
        "                USING src_fights s\n",
        "                ON t.event_id = s.event_id AND t.competition_id = s.competition_id\n",
        "                WHEN NOT MATCHED THEN INSERT *\n",
        "            \"\"\")\n",
        "print(\"Fights silver upserted\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview AFTER cleaning (fights)\n",
        "display(spark.table(f\"hive_metastore.{silver_db}.espn_fights_silver\").orderBy(F.desc(\"event_date\"), F.asc(\"card_order\")).limit(30))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
