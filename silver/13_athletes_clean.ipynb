{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UFC Athletes Transform & Clean (Bronze -> Silver)\n",
        "\n",
        "Cleans and writes `espn_athletes_silver` from bronze `espn_athletes`. Shows BEFORE/AFTER previews and drops near-empty columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime, timezone\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "try:\n",
        "    dbutils.widgets.text(\"storage_account\", \"storagetmufc\")\n",
        "    dbutils.widgets.text(\"secret_scope\", \"kv-scope\")\n",
        "    dbutils.widgets.text(\"key_name\", \"adls-account-key\")\n",
        "    dbutils.widgets.text(\"bronze_db\", \"ufc_bronze\")\n",
        "    dbutils.widgets.text(\"silver_db\", \"ufc_silver\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "bronze_db = dbutils.widgets.get(\"bronze_db\") if 'dbutils' in globals() else \"ufc_bronze\"\n",
        "silver_db = dbutils.widgets.get(\"silver_db\") if 'dbutils' in globals() else \"ufc_silver\"\n",
        "\n",
        "try:\n",
        "    storage_account = dbutils.widgets.get(\"storage_account\")\n",
        "    secret_scope = dbutils.widgets.get(\"secret_scope\")\n",
        "    key_name = dbutils.widgets.get(\"key_name\")\n",
        "    account_key = dbutils.secrets.get(secret_scope, key_name)\n",
        "    spark.conf.set(f\"fs.azure.account.key.{storage_account}.dfs.core.windows.net\", account_key)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    spark.sql(\"USE CATALOG hive_metastore\")\n",
        "except Exception:\n",
        "    try:\n",
        "        spark.catalog.setCurrentCatalog(\"hive_metastore\")\n",
        "    except Exception:\n",
        "        pass\n",
        "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {bronze_db}\")\n",
        "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {silver_db}\")\n",
        "try:\n",
        "    spark.catalog.setCurrentDatabase(bronze_db)\n",
        "except Exception:\n",
        "    spark.sql(f\"USE DATABASE {bronze_db}\")\n",
        "print(\"Bronze DB:\", bronze_db, \"| Silver DB:\", silver_db)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BEFORE preview\n",
        "_ath = spark.table(f\"hive_metastore.{bronze_db}.espn_athletes\")\n",
        "print(\"Athletes rows:\", _ath.count())\n",
        "display(_ath.orderBy(F.col(\"full_name\")).limit(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean & write silver\n",
        "SPARSE_THRESHOLD = 0.98\n",
        "w = Window.partitionBy(\"athlete_id\").orderBy(F.desc(\"ingestion_date\"), F.desc(\"run_id\"))\n",
        "\n",
        "ath1 = (_ath\n",
        "    .withColumn(\"full_name\", F.trim(\"full_name\"))\n",
        "    .withColumn(\"display_name\", F.trim(\"display_name\"))\n",
        "    .withColumn(\"country\", F.trim(\"country\"))\n",
        "    .withColumn(\"stance\", F.trim(\"stance\"))\n",
        "    .withColumn(\"weight_class\", F.trim(\"weight_class\"))\n",
        "    .withColumn(\"team\", F.trim(\"team\"))\n",
        "    .withColumn(\"combat_style\", F.trim(\"combat_style\"))\n",
        "    .withColumn(\"rn\", F.row_number().over(w)).filter(\"rn=1\").drop(\"rn\")\n",
        ")\n",
        "\n",
        "rows_cnt = ath1.count()\n",
        "null_map = {c: (ath1.filter(F.col(c).isNull()).count()/rows_cnt if rows_cnt else 0.0) for c in ath1.columns}\n",
        "core_keep = {\"athlete_id\",\"full_name\",\"display_name\",\"birth_date\"}\n",
        "optional = [\"country\",\"height\",\"height_cm\",\"reach_cm\",\"stance\",\"weight_class\",\"team\",\"combat_style\",\"image_url\"]\n",
        "keep_cols = list(core_keep) + [c for c in optional if null_map.get(c,0.0) < SPARSE_THRESHOLD]\n",
        "\n",
        "out = ath1.select(*keep_cols + [\"ingestion_date\",\"run_id\"])  # include technical columns for incremental\n",
        "\n",
        "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {silver_db}\")\n",
        "\n",
        "table_name = f\"hive_metastore.{silver_db}.espn_athletes_silver\"\n",
        "exists = False\n",
        "try:\n",
        "    spark.table(table_name)\n",
        "    exists = True\n",
        "except Exception:\n",
        "    exists = False\n",
        "\n",
        "if not exists:\n",
        "    out.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\").saveAsTable(table_name)\n",
        "else:\n",
        "    tgt = spark.table(table_name).select(\"athlete_id\", \"ingestion_date\", \"run_id\").alias(\"t\")\n",
        "    incr = (out.alias(\"s\")\n",
        "        .join(tgt, on=\"athlete_id\", how=\"left\")\n",
        "        .where(F.col(\"t.athlete_id\").isNull() | (F.col(\"s.ingestion_date\") > F.col(\"t.ingestion_date\")) | ((F.col(\"s.ingestion_date\") == F.col(\"t.ingestion_date\")) & (F.col(\"s.run_id\") > F.col(\"t.run_id\"))))\n",
        "        .select(\"s.*\")\n",
        "    )\n",
        "    incr.createOrReplaceTempView(\"src_athletes\")\n",
        "    spark.sql(f\"\"\"\n",
        "        MERGE INTO {table_name} t\n",
        "        USING src_athletes s\n",
        "        ON t.athlete_id = s.athlete_id\n",
        "        WHEN MATCHED AND (t.ingestion_date < s.ingestion_date OR (t.ingestion_date = s.ingestion_date AND t.run_id < s.run_id)) THEN UPDATE SET *\n",
        "        WHEN NOT MATCHED THEN INSERT *\n",
        "    \"\"\")\n",
        "print(\"Athletes silver upserted; kept columns:\", out.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AFTER preview\n",
        "_display = spark.table(f\"hive_metastore.{silver_db}.espn_athletes_silver\").orderBy(F.col(\"full_name\"))\n",
        "display(_display.limit(20))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
